{-
   This module exposes the API to build rest
   applications
--}
module chinook.Chinook where

import chinook.Core as Core
import chinook.Router as Router
import chinook.Spark as Spark
import chinook.Utils (blank)

import frege.java.Util (Set, Map)
import frege.data.Iterators (ArrayIterator)

{--
   Converts a mutable request in an immutable data structure
-}
toChinookRequest :: MutableIO Spark.Request -> IO Core.Request
toChinookRequest source = do
  sQueryParams  <- convertQueryParams source
  sHeaders      <- convertHeaders     source
  sPathParams   <- convertPathParams  source
  sBody         <- convertBody        source
  return $ Request { headers     = sHeaders,
                     queryParams = sQueryParams,
                     pathParams  = sPathParams,
                     body        = sBody }

{--
    Extracts query params from a mutable structure to a list of
    `QueryParam` values. When getting a list from the QueryMap it
    gives us a list of [(String, JArray String)] so we need to
    convert it to [(String, [String])]
-}
convertQueryParams :: MutableIO Spark.Request -> IO [(String, [String])]
convertQueryParams request = do
  mQueryMap   <- Spark.Request.queryMap request
  mMap        <- Spark.QueryMap.toMap mQueryMap
  list        <- Map.toList mMap
  return $ map fromArrayToList list

-- We need to transform String arrays to [String]
fromArrayToList :: (String, JArray String) -> (String, [String])
fromArrayToList (st, arr) = (st, (ArrayIterator.from(arr)).toList)

{--
   Extracts all headers coming from a mutable structure to a
   list of `Header` values
-}
convertHeaders :: MutableIO Spark.Request -> IO [(String, Maybe String)]
convertHeaders request = do
  mutableNames  <- Spark.Request.allHeaders request
  names         <- Set.toList mutableNames
  values        <- sequence $ map (Spark.Request.headers request) names
  return $ zip names values

{--
    Extracts path params coming from a mutable structure into a list of
    `PathParam` values
-}
convertPathParams :: MutableIO Spark.Request -> IO [(String, String)]
convertPathParams source = do
  mutable <- Spark.Request.allPaths source
  tuples  <- Map.toList mutable
  return tuples

convertBody :: MutableIO Spark.Request -> IO (Maybe String)
convertBody source = do
  Spark.Request.body source

-- __      __       _
-- \ \    / /      | |
--  \ \  / /__ _ __| |__  ___
--   \ \/ / _ \ '__| '_ \/ __|
--    \  /  __/ |  | |_) \__ \
--     \/ \___|_|  |_.__/|___/
--

{--
   Creates an HTTP GET endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO (Maybe String).

-}
-- tag::getFunction[]
get  :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::getFunction[]
get path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.get path route

{--
   Creates an HTTP POST endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
post :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
post path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.post path route

{--
   Creates an HTTP DELETE endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
-- tag::deleteFunction[]
delete :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::deleteFunction[]
delete path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.delete path route

{--
   Creates an HTTP PUT endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
-- tag::putFunction[]
put :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::putFunction[]
put path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.put path route

{--
   Creates an HTTP PATCH endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
-- tag::patchFunction[]
patch :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::patchFunction[]
patch path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.patch path route

{--
   Creates an HTTP OPTIONS endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
-- tag::optionsFunction[]
options :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::optionsFunction[]
options path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.options path route

{--
   Creates an TRACE endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
-- tag::traceFunction[]
trace :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::traceFunction[]
trace path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.trace path route

{--
   Creates an CONNECT endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
-- tag::connectFunction[]
connect :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::connectFunction[]
connect path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.connect path route

{--
   Creates an HEAD endpoint. It receives:

   - A path
   - A function handling the request

   The function is a lambda function receiving a chinook.Request
   and a chinook.Response and returns an IO ().

-}
-- tag::connectFunction[]
head :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::connectFunction[]
head path lambda = do
  route <- toSparkRoute lambda
  Spark.Rest.head path route

-- tag::beforeFilter[]
before :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::beforeFilter[]
before path lambda = do
  route <- toSparkFilter lambda
  Spark.Rest.before path route

-- tag::afterFilter[]
after :: String -> (IO Core.Request -> IO Core.Response) -> IO ()
-- end::afterFilter[]
after path lambda = do
  route <- toSparkFilter lambda
  Spark.Rest.after path route

{--
   Takes the response generated in a Chinook Handler and converts that response
   in a Spark valid response
-}
applyChinookResponseToSpark :: Core.Response -> MutableIO Spark.Response -> IO ()
applyChinookResponseToSpark response spark = do
    setSparkStatus  response.status  spark
    setSparkOutput  response.output  spark
    setSparkHeaders response.headers spark

{--
   When processing an interceptor if the result response has the `halting` property
   set to true, then the process should be stopped
-}
applyPossibleHalt :: Core.Response -> MutableIO Spark.Response -> IO ()
applyPossibleHalt response spark = if (response.halting == true)
                                   then Spark.Rest.halt response.status response.output
                                   else return ()

setSparkStatus  :: Int -> MutableIO Spark.Response  -> IO ()
setSparkStatus status response = response.status status

setSparkOutput  :: Maybe String -> MutableIO Spark.Response  -> IO ()
setSparkOutput output response = case output of
    Just output -> response.body output
    Nothing     -> response.body ""

setSparkHeaders :: [(String, Maybe String)] -> MutableIO Spark.Response -> IO ()
setSparkHeaders []     response = return ()
setSparkHeaders (x:xs) response = case x of
    (a, Just b) -> response.header a b
    _           -> setSparkHeaders xs response

-- Converts a handler to a Spark route instance
toSparkRoute :: (IO Core.Request -> IO Core.Response) -> IO (MutableIO Route)
toSparkRoute lambda = Spark.Route.new $ toSparkOutput $ \req \res -> do
    response <- lambda $ toChinookRequest req
    applyChinookResponseToSpark response res
    return $ response.output

-- Converts an interceptor to a Spark filter instance
toSparkFilter :: (IO Core.Request -> IO Core.Response) -> IO (MutableIO Filter)
toSparkFilter lambda = Spark.Filter.new $ toSparkFilterOutput $ \req \res -> do
    response <- lambda $ toChinookRequest req
    applyChinookResponseToSpark response res
    applyPossibleHalt response res
    return $ response.output

toSparkFilterOutput :: (a -> b -> IO (Maybe String)) -> (a -> b -> IO ())
toSparkFilterOutput fn1 request response = do
  result <- fn1 request response
  return ()

{--
  While within Frege we want to work with safe abstractions like
  Maybe or Either, Spark needs to receive a concrete Java type.
  This transformation narrows the gap between both worlds.

  Apart from this function, there is also another part of the
  bridge between Frege->Spark written in Spark.Rest.java
-}
toSparkOutput :: (a -> b -> IO (Maybe String)) -> (a -> b -> IO String)
toSparkOutput fn1 request response = do
  result <- fn1 request response
  return $ fromMaybe blank result

{--
  Maps between `Router.Resource` mappings to realworld
  endpointgs
-}
convertRoute :: Router.Resource -> IO ()
convertRoute route = case route of
  Router.Get     path handler -> get     path handler
  Router.Post    path handler -> post    path handler
  Router.Put     path handler -> put     path handler
  Router.Delete  path handler -> delete  path handler
  Router.Patch   path handler -> patch   path handler
  Router.Options path handler -> options path handler
  Router.Trace   path handler -> trace   path handler
  Router.Head    path handler -> head    path handler
  Router.Before  path handler -> before  path handler
  Router.After   path handler -> after   path handler
  Router.Family  path routes  -> mapM_ convertRoute routes

{--
  Settings like application available port or static files
  location are represented by `Configuration`. Instead of
  using (String,String) pairs, it seems to be safer to use
  types to represent those settings, e.g instead of
  writing ("port", "808x") and receive a runtime error it's
  better to write `port 8080` which is checked at compile time.
-}
-- tag::configuration[]
data Configuration = IntConfig String Int    |
                     StrConfig String String
-- end::configuration[]

--- Creates settings for service port
-- tag::port[]
port :: Int -> Configuration
-- end::port[]
port number = IntConfig "port" number

--- Creates settings for static files location
-- tag::staticFiles[]
staticFiles :: String -> Configuration
-- end::staticFiles[]
staticFiles path = StrConfig "staticFileLocation" path

--- Translates `Configuration` values to real world settings
configure :: Configuration -> IO ()
configure cfg = case cfg of
  IntConfig "port" value               -> Spark.Config.port value
  StrConfig "staticFileLocation" value -> Spark.Config.staticFileLocation value
  _                                    -> return ()

{--
  Bootstraps the application. It receives configuration
  settings as well as the resource mappings
-}
run :: [Configuration] -> [Resource] -> IO ()
run cfg mappings = do
  _ <- mapM_ configure cfg
  mapM_ convertRoute mappings
